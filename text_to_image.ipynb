{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecddf268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce140d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "transform = transforms.Compose([transforms.Resize(image_size), transforms.CenterCrop(image_size), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "IMAGE_PATH = './archive/img_align_celeba/'\n",
    "\n",
    "dset = dataset.ImageFolder(root = IMAGE_PATH, transform = transform)\n",
    "dataloader = utils.data.DataLoader(dset, batch_size = 128, shuffle = True, num_workers = 2, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d13785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZING THE DATA\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.axis('off')\n",
    "plt.title('Training Images')\n",
    "plt.imshow(np.transpose((vutils.make_grid(real_batch[0].to(device)[:64], padding = 2, normalize = True)).cpu().numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e38dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM WEIGHT INITIALIZATION\n",
    "def weight_init(instance):\n",
    "    classname = instance.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(instance.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(instance.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(instance.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db1c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISCRIMINATOR MODEL\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        self.conv2_bn = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        self.conv3_bn = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        self.conv4_bn = nn.BatchNorm2d(512)\n",
    "        self.conv5 = nn.Conv2d(512, 1, kernel_size = 4, stride = 1, padding = 0, bias = False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 64, 64)\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2, inplace = True)\n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(self.conv2_bn(x), 0.2, inplace = True)\n",
    "        x = self.conv3(x)\n",
    "        x = F.leaky_relu(self.conv3_bn(x), 0.2, inplace = True)\n",
    "        x = self.conv4(x)\n",
    "        x = F.leaky_relu(self.conv4_bn(x), 0.2, inplace = True)\n",
    "        x = self.conv5(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        out = x.view(-1, 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fef5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATOR MODEL\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_transpose1 = nn.ConvTranspose2d(100, 512, kernel_size = 4, stride = 1, padding = 0, bias = False)\n",
    "        self.conv_transpose1_bn = nn.BatchNorm2d(512)\n",
    "        self.conv_transpose2 = nn.ConvTranspose2d(512, 256, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        self.conv_transpose2_bn = nn.BatchNorm2d(256)\n",
    "        self.conv_transpose3 = nn.ConvTranspose2d(256, 128, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        self.conv_transpose3_bn = nn.BatchNorm2d(128)\n",
    "        self.conv_transpose4 = nn.ConvTranspose2d(128, 64, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        self.conv_transpose4_bn = nn.BatchNorm2d(64)\n",
    "        self.conv_transpose5 = nn.ConvTranspose2d(64, 3, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 100, 1, 1)\n",
    "        x = self.conv_transpose1(x)\n",
    "        x = F.relu(self.conv_transpose1_bn(x), inplace = True)\n",
    "        x = self.conv_transpose2(x)\n",
    "        x = F.relu(self.conv_transpose2_bn(x), inplace = True)\n",
    "        x = self.conv_transpose3(x)\n",
    "        x = F.relu(self.conv_transpose3_bn(x), inplace = True)\n",
    "        x = self.conv_transpose4(x)\n",
    "        x = F.relu(self.conv_transpose4_bn(x), inplace = True)\n",
    "        x = self.conv_transpose5(x)\n",
    "        out = torch.tanh(x)\n",
    "        \n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE MODEL INSTANCE\n",
    "D = Discriminator()\n",
    "D = D.to(device)\n",
    "D = D.float()\n",
    "D.apply(weight_init)\n",
    "print(D)\n",
    "\n",
    "G = Generator()\n",
    "G = G.to(device)\n",
    "G = G.float()\n",
    "G.apply(weight_init)\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b26cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING LOSSES\n",
    "loss = nn.BCELoss()\n",
    "def real_loss_fn(real_out):\n",
    "    labels = torch.ones(real_out.size()[0], 1).to(device)\n",
    "    loss_real = loss(real_out.squeeze(), labels.squeeze())\n",
    "    return loss_real\n",
    "\n",
    "def fake_loss_fn(fake_out):\n",
    "    labels = torch.zeros(fake_out.size()[0], 1).to(device)\n",
    "    loss_fake = loss(fake_out.squeeze(), labels.squeeze())\n",
    "    return loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af95641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINIG OPTIMIZERS\n",
    "disc_opt = optim.Adam(D.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "gen_opt = optim.Adam(G.parameters(), lr = 0.0002, betas = (0.5, 0.999)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e79d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(D, G, dataloader, disc_opt, gen_opt, num_epochs, fac, batch_size = 128):\n",
    "    \n",
    "    disc_losses = []\n",
    "    gen_losses = []\n",
    "    \n",
    "    fixed_noise = torch.randn(64, 100).to(device)\n",
    "    \n",
    "    D.train()\n",
    "    G.train()\n",
    "    \n",
    "    for epoch in range(num_epochs + 1):\n",
    "        \n",
    "        gen_loss_total = 0\n",
    "        disc_loss_total = 0\n",
    "        \n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            disc_opt.zero_grad()\n",
    "            \n",
    "            x = data[0].to(device)\n",
    "            real_out = D(x.float())\n",
    "            real_loss = real_loss_fn(real_out)\n",
    "            \n",
    "            gen_in1 = torch.randn(batch_size, 100).to(device)\n",
    "            disc_gen_in1 = G(gen_in1.float()).detach()\n",
    "            fake_out = D(disc_gen_in1.float())\n",
    "            fake_loss = fake_loss_fn(fake_out)\n",
    "            \n",
    "            disc_loss = real_loss + fake_loss\n",
    "            disc_loss_total += disc_loss\n",
    "            \n",
    "            disc_loss.backward()\n",
    "            disc_opt.step()\n",
    "            \n",
    "            gen_opt.zero_grad()\n",
    "            \n",
    "            gen_in2 = torch.randn(batch_size, 100).to(device)\n",
    "            disc_gen_in2 = G(gen_in2.float())\n",
    "            real_fake_out = D(disc_gen_in2.float())\n",
    "            gen_loss = real_loss_fn(real_fake_out)\n",
    "            gen_loss_total += gen_loss\n",
    "            \n",
    "            gen_loss.backward()\n",
    "            gen_opt.step()\n",
    "            \n",
    "        disc_losses.append(disc_loss_total)\n",
    "        gen_losses.append(gen_loss_total)\n",
    "        print(\"Epoch \", epoch, \" - \", \"Discriminator Loss: \", disc_loss_total/len(dataloader), \" Generator Loss: \", gen_loss_total/len(dataloader))\n",
    "        \n",
    "        if epoch % fac == 0:\n",
    "            G.eval()\n",
    "            sample_out = G(fixed_noise.float())\n",
    "            G.train()\n",
    "            \n",
    "            plt.figure(figsize = (8,8))\n",
    "            plt.axis('off')\n",
    "            \n",
    "            sample_out = vutils.make_grid(sample_out, padding = 2, normalize = True).cpu().detach().numpy()\n",
    "            sample_out = np.transpose(sample_out, (1, 2, 0))\n",
    "            plt.imshow(sample_out)\n",
    "            \n",
    "    return disc_losses, gen_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c11000",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_losses, gen_losses = train(D, G, dataloader, disc_opt, gen_opt, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09809fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTTING LOSSES\n",
    "disc_losses = np.array(disc_losses)\n",
    "gen_losses = np.array(gen_losses)\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.title('Discriminator and Generator Losses')\n",
    "plt.plot(disc_losses, label = 'Discriminator')\n",
    "plt.plot(gen_losses, label = 'Generator')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec3ef11d5736e139d6fae840187e0e1cf58b8f95a3276ae1edd96183e0004bd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
